{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import AlignIO\n",
    "import sys, h5py\n",
    "sys.path.append('../..')\n",
    "import mutagenesisfunctions as mf\n",
    "import time as time\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build model from seed\n",
    "! cmbuild ../../data_RFAM/RF01739.cm ../data_RFAM/seeds/RF01739.sto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#emit sequences from alignment\n",
    "! cmemit -a -N 100000 --seed 274 -o ../../data_RFAM/glnAsim_100k.sto ../../data_RFAM/RF01739.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#open file\n",
    "filename = '../data_RFAM/riboswitch_100k.sto'\n",
    "alignment = AlignIO.read(open(filename), \"stockholm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open positive control: 31.3s\n"
     ]
    }
   ],
   "source": [
    "#Open positive control simulated sequences\n",
    "starttime = time.time()\n",
    "simalign_file = '../data_RFAM/trnasim_100k.sto'\n",
    "Xpos = mf.sto_onehot(simalign_file, 'rna')\n",
    "Xpos = np.expand_dims(Xpos, axis=2)\n",
    "print ('Open positive control: ' + mf.sectotime(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simalign_file = '../data_RFAM/trnasim_100k.sto'\n",
    "\n",
    "#Get the full secondary structure and sequence consensus from the emission\n",
    "SS = mf.getSSconsensus(simalign_file)\n",
    "SQ = mf.getSQconsensus(simalign_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the ungapped sequence and the indices of ungapped nucleotides\n",
    "_, ugSS, ugidx = mf.rm_consensus_gaps(X_data, SS)\n",
    "_, ugSQ, _ = mf.rm_consensus_gaps(X_data, SQ)\n",
    "len(ugidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the gapped indices in the consensus SS\n",
    "gapidx = mf.consensus_gaps(SS)\n",
    "len(gapidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the sequence and indices of the conserved base pairs\n",
    "bpchars = ['(',')','<','>','{','}']\n",
    "sig_bpchars = ['<','>']\n",
    "bpidx, bpSS, nonbpidx = mf.sigbasepair(SS, bpchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative control generated randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make negative controls\n",
    "starttime = time.time()\n",
    "numdata, seqlen, _, dims = Xpos.shape\n",
    "dims = dims-1\n",
    "SS = mf.getSSconsensus(simalign_file)\n",
    "Xneg = mf.seq_generator_gaps(SS, numdata, seqlen, dims, pgaps=(0.,0.))\n",
    "print ('Random sequence generation completed in: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative control with copies of everything that is not a base pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making neg control w/o base pairs: 6.71s\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#insert non base pair positive control things into negative control\n",
    "for s in range(Xpos.shape[0]):\n",
    "    Xneg[s, nonbpidx, :, :] = np.copy(Xpos[s, nonbpidx, :, :])\n",
    "\n",
    "print ('Making neg control w/o base pairs: ' + mf.sectotime(time.time() - starttime))\n",
    "\n",
    "#check\n",
    "if Xneg[:, gapidx, :, :].all() == Xpos[:, gapidx, :, :].all():\n",
    "    print ('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative control with copies of just the gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making neg control w/ copy of pos control gaps: 1.05s\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#insert gaps in the negative control where there were gaps in the positive control\n",
    "for s in range(Xpos.shape[0]):\n",
    "    gapidxcopy = np.where(Xpos[s,:,0,4]==1.)[0]\n",
    "    Xneg[s, gapidxcopy, :, :] = np.array([0., 0. , 0. ,0., 1.])\n",
    "    \n",
    "print ('Making neg control w/ copy of pos control gaps: '\n",
    "       + mf.sectotime(time.time() - starttime))\n",
    "\n",
    "#check\n",
    "if np.sum(Xneg[:,:,:,4]) == np.sum(Xpos[:,:,:,4]):\n",
    "    print ('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative control emmitted from a mean profile of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Emit sequences from the positive control profile\n",
    "Xprofile = np.squeeze(np.mean(Xpos, axis=0))\n",
    "numdata, seqlen, _, dims = Xpos.shape\n",
    "dims = dims-1\n",
    "Xneg = mf.seq_generator_profile(Xprofile, numdata, seqlen, dims)\n",
    "\n",
    "print ('Making neg control emitted from frequency profile: '\n",
    "       + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative control as a shuffled positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making neg control as shuffled pos: 5.35s\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Create a negative control of randomly suffled sequences\n",
    "numdata, seqlen, _, dims = Xpos.shape\n",
    "dims = dims-1\n",
    "\n",
    "def seq_bunchshuffle(Xpos, numdata, seqlen, bunchsize=(10, 75)):\n",
    "\n",
    "    #n = the number of bunches\n",
    "    smallbunch, largebunch = bunchsize\n",
    "    n_upper = seqlen//smallbunch\n",
    "    n_lower = seqlen//largebunch\n",
    "\n",
    "    Xshuffle = np.zeros((np.shape(Xpos)))\n",
    "    ns = []\n",
    "    for seq in range(numdata):\n",
    "        Xcopy = np.copy(Xpos[seq])\n",
    "\n",
    "        n = np.random.randint(n_lower, n_upper)\n",
    "\n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        randidx = np.random.permutation(n)\n",
    "        for i in range(n):\n",
    "            idx = randidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            Xshuffle[seq, start:start+space, :, :] = Xcopy[bunchidx[idx]:bunchidx[idx+1], :, :]\n",
    "            start = start + space\n",
    "            \n",
    "    return (Xshuffle)\n",
    "\n",
    "\n",
    "Xnegshuffle = seq_bunchshuffle(Xpos, numdata, seqlen)\n",
    "\n",
    "print ('Making neg control as shuffled pos: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rejoin pos and neg controls\n",
    "X_data = np.concatenate((Xpos, Xneg), axis=0)\n",
    "numdata, seqlen, _, dims = X_data.shape\n",
    "dims = dims-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make Y data\n",
    "Y_data = np.zeros((numdata, 1))\n",
    "Y_data[:numdata//2, :] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Can't prepare for writing data (File write failed: time = tue jul  3 17:34:45 2018\n, filename = '../data_rfam/trna_100k_d5.hdf5', file descriptor = 76, errno = 28, error message = 'no space left on device', buf = 0x7f83c87d47b0, total write size = 2534931040, bytes this sub-write = 2534931040, bytes actually written = 18446744073709551615, offset = 1569071104)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f1069c3c21f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhdf5path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data_RFAM/trna_100k_d5.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peter/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peter/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mdset_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_objects.c:2856)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_objects.c:2814)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/h5d.c:3687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_proxy.c:2031)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_proxy.c:1741)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Can't prepare for writing data (File write failed: time = tue jul  3 17:34:45 2018\n, filename = '../data_rfam/trna_100k_d5.hdf5', file descriptor = 76, errno = 28, error message = 'no space left on device', buf = 0x7f83c87d47b0, total write size = 2534931040, bytes this sub-write = 2534931040, bytes actually written = 18446744073709551615, offset = 1569071104)"
     ]
    }
   ],
   "source": [
    "#Save dictionaries into h5py files\n",
    "hdf5path = '../data_RFAM/trna_100k_d5.hdf5'\n",
    "with h5py.File(hdf5path, 'w') as f:\n",
    "    f.create_dataset('X_data', data=X_data)\n",
    "    f.create_dataset('Y_data', data=Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction completed in: 1.10670185089s\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Open data from h5py\n",
    "\n",
    "data_path = '../data_RFAM/trna_100k_d3.hdf5'\n",
    "with h5py.File(data_path, 'r') as dataset:\n",
    "    X_data = np.array(dataset['X_data'])\n",
    "    Y_data = np.array(dataset['Y_data'])\n",
    "    \n",
    "num_data, seq_length, _, dims = X_data.shape\n",
    "dims = dims-1\n",
    "    \n",
    "print ('Data extraction completed in: ' + str(time.time() - starttime) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xpos = X_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffleportion = np.random.permutation(100000)[:25000]\n",
    "X_data[100000:125000] = Xnegshuffle[shuffleportion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 513, 1, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove gaps from sequences\n",
    "ungapped = True\n",
    "if ungapped:\n",
    "    X_data = X_data[:, :, :, :dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get validation and test set from training set\n",
    "test_frac = 0.3\n",
    "valid_frac = 0.1\n",
    "N = numdata\n",
    "split_1 = int(N*(1-valid_frac-test_frac))\n",
    "split_2 = int(N*(1-test_frac))\n",
    "shuffle = np.random.permutation(N)\n",
    "\n",
    "#set up dictionaries\n",
    "train = {'inputs': X_data[shuffle[:split_1]], \n",
    "         'targets': Y_data[shuffle[:split_1]]}\n",
    "valid = {'inputs': X_data[shuffle[split_1:split_2]], \n",
    "         'targets': Y_data[shuffle[split_1:split_2]]}\n",
    "test = {'inputs': X_data[shuffle[split_2:]], \n",
    "         'targets': Y_data[shuffle[split_2:]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction and dict construction completed in: 2s\n"
     ]
    }
   ],
   "source": [
    "print ('Data extraction and dict construction completed in: %ds' %2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
