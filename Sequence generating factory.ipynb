{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, h5py, os\n",
    "sys.path.append('../..')\n",
    "import mutagenesisfunctions as mf\n",
    "import time as time\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(274)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL OF THESE SEQUENCES ARE IN THEIR IDX FORM, NOT HOTPLOT\n",
    "#sequence generator function\n",
    "def randomsequence(N, maxsize, sample=False):\n",
    "    if sample:\n",
    "        seq_sizes = np.random.randint(1, maxsize, size=N)\n",
    "    else:\n",
    "        seq_sizes = (np.ones((N))*maxsize).astype(int)\n",
    "        \n",
    "    seq_idxs = []\n",
    "    for seq_size in seq_sizes:\n",
    "        seq_idx = np.random.randint(0,4, size=seq_size)\n",
    "        seq_idxs.append(list(seq_idx))\n",
    "    return (seq_idxs)\n",
    "\n",
    "#stem region generator\n",
    "def stemregion(N, maxsize, sample=False):\n",
    "    stem1 = randomsequence(N, maxsize, sample=sample)\n",
    "    #generate reverse complement of stem1\n",
    "    bpref = {0:3, 1:2, 2:1, 3:0}\n",
    "    stem2 = []\n",
    "    for s in stem1:\n",
    "        seq_idx = [bpref[n] for n in s]\n",
    "        stem2.append(seq_idx[::-1])\n",
    "    \n",
    "    return (stem1, stem2)\n",
    "\n",
    "#CONVERT IDX TO ONEHOT\n",
    "def onehot(sequence):\n",
    "    length = len(sequence)\n",
    "    onehotseq = np.zeros((length, 4))\n",
    "    for i,s in enumerate(sequence):\n",
    "        onehotseq[i, s] = 1.\n",
    "    return (onehotseq.astype(np.float32))\n",
    "\n",
    "#SAVE THE DATA\n",
    "def savehdf5(hdf5path, X_data, Y_data):\n",
    "    with h5py.File(hdf5path, 'w') as f:\n",
    "        f.create_dataset('X_data', data=X_data.astype(np.float32), compression='gzip')\n",
    "        f.create_dataset('Y_data', data=Y_data.astype(np.float32), compression='gzip')\n",
    "    print ('Saving data to %s'%(hdf5path))\n",
    "    \n",
    "#OPEN THE DATA\n",
    "def openhdf5(hdf5path):\n",
    "    with h5py.File(hdf5path, 'r') as dataset:\n",
    "        X_data = np.array(dataset['X_data'])\n",
    "        Y_data = np.array(dataset['Y_data'])\n",
    "    return (X_data, Y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hairpin Generation Factory\n",
    "\n",
    "This notebook will serve as an easy way to generate toy hairpin sequences with all features of the data controlable. To make generation easy, there are 2 functions that will generate that will create the first outer loop, the two stem regions, the inner loop and the second outer loop which will then be stitched together at the end. Additionally, for each dataset generated, a negative chimeric control should be made for which there is fucnction.\n",
    "\n",
    "Variable kinds of hairpins that can be made, eg:\n",
    "1. Hairpins with variable buffers\n",
    "2. Same length sequences with stem regions in different locations\n",
    "3. Stem regions of different sizes \n",
    "4. Outer loops of different sizes\n",
    "5. (maybe) hairpins with gaps in them through which we can test RNNs on as a positive control for RNN experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildhp(stemsize, Oloopsize, Iloopsize, numstems=1, numOloops=2, numIloops=1):\n",
    "    Oloops = [randomsequence(1,Oloopsize)[0] for l in range(numOloops)]\n",
    "    Iloops = [randomsequence(1,Iloopsize)[0] for l in range(numIloops)]\n",
    "    \n",
    "    stem1s = []\n",
    "    stem2s = []\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    stems = np.vstack([stem1s[0], stem2s[0]])\n",
    "    \n",
    "    #assemble\n",
    "    hp_idx = Oloops[0] + list(stems[0]) + Iloops[0] + list(stems[1]) + Oloops[1]\n",
    "    return(hp_idx)\n",
    "\n",
    "def buildhp_full(stemsize, Oloopsize, Iloopsize, numstems=1, numOloops=2, numIloops=1):\n",
    "    Oloops = [randomsequence(1,Oloopsize[l])[0] for l in range(numOloops)]\n",
    "    Iloops = [randomsequence(1,Iloopsize)[0] for l in range(numIloops)]\n",
    "    \n",
    "    stem1s = []\n",
    "    stem2s = []\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    stems = np.vstack([stem1s[0], stem2s[0]])\n",
    "    \n",
    "    #assemble\n",
    "    hp_idx = Oloops[0] + list(stems[0]) + Iloops[0] + list(stems[1]) + Oloops[1]\n",
    "    return(hp_idx)\n",
    "\n",
    "def neghp(X_pos):\n",
    "    numdata, seqlen, _ = X_pos.shape\n",
    "    firsthalf = X_pos[:, :seqlen//2, :]\n",
    "    secondhalf = X_pos[:, seqlen//2:, :]\n",
    "    shuffle1 = np.random.permutation(firsthalf)\n",
    "    shuffle2 = np.random.permutation(secondhalf)\n",
    "    X_neg = np.concatenate((shuffle1, shuffle2), axis=1)\n",
    "    return (X_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to ../data_toyhp/toyhp_50k_mod.hdf5\n"
     ]
    }
   ],
   "source": [
    "import time as time\n",
    "starttime = time.time()\n",
    "\n",
    "#set up trials\n",
    "trial_names = ['mod']#['small', 'med', 'large']\n",
    "small = (5, 5, 8)\n",
    "mod = (6, 8, 7)\n",
    "med = (11, 7, 6)\n",
    "large = (22, 14, 12)\n",
    "trials = [mod]#[small, med, large]\n",
    "\n",
    "num = 50000\n",
    "\n",
    "#set up save parameters\n",
    "exp_name = 'toyhp'\n",
    "exp_folder = 'data_%s'%(exp_name)\n",
    "\n",
    "\n",
    "for ii, t in enumerate(trials):\n",
    "    stemsize, Iloopsize, Oloopsize = t\n",
    "\n",
    "    #Build X_pos\n",
    "    X_pos = np.asarray([onehot(buildhp(stemsize=stemsize, Oloopsize=Oloopsize, Iloopsize=Iloopsize)) for r in range(num)])\n",
    "    #Build X_neg as a shuffled chimera\n",
    "    X_neg = neghp(X_pos)\n",
    "\n",
    "    X_data = np.vstack((X_pos, X_neg))\n",
    "\n",
    "    #Build Y labels\n",
    "    Y_data = np.zeros((num*2, 1))\n",
    "    Y_data[:num, :] = 1.\n",
    "    \n",
    "    #Save\n",
    "    filename = '%s_%0.fk_%s.hdf5'%(exp_name, num//1000, trial_names[ii])\n",
    "    savepath = os.path.join('..', exp_folder, filename)\n",
    "    savehdf5(savepath, X_data, Y_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offcenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to ../data_toyhp/toyhp_50k_offcenter.hdf5\n"
     ]
    }
   ],
   "source": [
    "full_len = 41\n",
    "num = 50000\n",
    "\n",
    "stemsize = 11\n",
    "Iloopsize = 7\n",
    "\n",
    "mean_offidx, std_offidx = (6, 2)\n",
    "offidxs = np.clip(np.random.normal(mean_offidx, std_offidx, num), a_max=10, a_min=2).astype(int)\n",
    "endloopsizes = full_len - 2*stemsize - Iloopsize - offidxs\n",
    "Oloopsize = zip(offidxs, endloopsizes)\n",
    "\n",
    "\n",
    "#set up save parameters\n",
    "exp_name = 'toyhp'\n",
    "exp_folder = 'data_%s'%(exp_name)\n",
    "trial = 'offcenter'\n",
    "\n",
    "#Build X_pos\n",
    "X_pos = np.asarray([onehot(buildhp_full(stemsize=stemsize, Oloopsize=Oloopsize[r], Iloopsize=Iloopsize)) for r in range(num)])\n",
    "#Build X_neg as a shuffled chimera\n",
    "X_neg = neghp(X_pos)\n",
    "\n",
    "X_data = np.vstack((X_pos, X_neg))\n",
    "\n",
    "#Build Y labels\n",
    "Y_data = np.zeros((num*2, 1))\n",
    "Y_data[:num, :] = 1.\n",
    "\n",
    "#Save\n",
    "filename = '%s_%0.fk_%s.hdf5'%(exp_name, num//1000, trial)\n",
    "savepath = os.path.join('..', exp_folder, filename)\n",
    "with h5py.File(savepath, 'w') as f:\n",
    "    f.create_dataset('X_data', data=X_data.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('Y_data', data=Y_data.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('offidxs', data=offidxs.astype(np.int8), compression='gzip')\n",
    "print ('Saving data to %s'%(savepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pseudoknot Generation\n",
    "\n",
    "We will model a simple pseudoknot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildpk(stemsize, loopsize, numstems=2, numloops=5):\n",
    "    loops = [randomsequence(1,loopsize)[0] for l in range(numloops)]\n",
    "\n",
    "    stem1s = []\n",
    "    stem2s = []\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    stems = np.vstack([stem1s[0], stem1s[1], stem2s[0], stem2s[1]])\n",
    "\n",
    "    #assemble\n",
    "    pk_idx = []\n",
    "    for ii in range(numloops):\n",
    "        pk_idx=pk_idx + loops[ii]\n",
    "        if ii <= len(stems)-1:\n",
    "            pk_idx=pk_idx+list(stems[ii])\n",
    "    return(pk_idx)\n",
    "\n",
    "def negpk(X_pos):\n",
    "    numdata, seqlen, _ = X_pos.shape\n",
    "    firsthalf = X_pos[:, :seqlen//2, :]\n",
    "    secondhalf = X_pos[:, seqlen//2:, :]\n",
    "    shuffle1 = np.random.permutation(firsthalf)\n",
    "    shuffle2 = np.random.permutation(secondhalf)\n",
    "    X_neg = np.concatenate((shuffle1, shuffle2), axis=1)\n",
    "    return (X_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a 50,000 large positive control set of pseudoknots with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.342957019805908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time as time\n",
    "starttime = time.time()\n",
    "\n",
    "stemsize = 6\n",
    "numstems = 2\n",
    "loopsize = 6\n",
    "numloops = 5\n",
    "num = 50000\n",
    "\n",
    "#Build X_pos\n",
    "X_pos = np.asarray([onehot(buildpk(stemsize=stemsize, loopsize=loopsize)) for r in range(num)])\n",
    "#Build X_neg as a shuffled chimera\n",
    "X_neg = negpk(X_pos)\n",
    "\n",
    "X_data = np.vstack((X_pos, X_neg))\n",
    "\n",
    "#Build Y labels\n",
    "Y_data = np.zeros((num*2, 1))\n",
    "Y_data[:num, :] = 1.\n",
    "\n",
    "              \n",
    "time.time() - starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data: 0.68s\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Save dictionaries into h5py files\n",
    "hdf5path = '../data_toypk/toypk_50_d2.hdf5'\n",
    "with h5py.File(hdf5path, 'w') as f:\n",
    "    f.create_dataset('X_data', data=X_data.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('Y_data', data=Y_data.astype(np.float32), compression='gzip')\n",
    "print ('Saving data: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction completed in: 0.31542301178s\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Open data from h5py\n",
    "\n",
    "hdf5path = '../data_toypk/toypk_50_d2.hdf5'\n",
    "with h5py.File(hdf5path, 'r') as dataset:\n",
    "    X_data = np.array(dataset['X_data'])\n",
    "    Y_data = np.array(dataset['Y_data'])\n",
    "    \n",
    "num_data, seq_length, dims = X_data.shape\n",
    "\n",
    "    \n",
    "print ('Data extraction completed in: ' + str(time.time() - starttime) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 54, 1, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = np.expand_dims(X_data, axis=2)\n",
    "\n",
    "X_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
