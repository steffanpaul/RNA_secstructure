{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from deepomics import neuralnetwork as nn\n",
    "from deepomics import utils, fit, visualize, saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load hairpin data\n",
    "data_path = 'data_peter/random_sequences_with_custom_hl.hdf5'\n",
    "with h5py.File(data_path) as dataset:\n",
    "    X_train_seq = np.expand_dims(np.array(dataset['train_seq']).transpose([0, 2, 1]), axis=2)\n",
    "    X_train_struct = np.expand_dims(np.array(dataset['train_structures']).transpose([0, 2, 1]), axis=2)\n",
    "    Y_train = np.expand_dims(np.array(dataset['train_targets']), axis=1)\n",
    "    X_test_seq = np.expand_dims(np.array(dataset['test_seq']).transpose([0, 2, 1]), axis=2)\n",
    "    X_test_struct = np.expand_dims(np.array(dataset['test_structures']).transpose([0, 2, 1]), axis=2)\n",
    "    Y_test = np.expand_dims(np.array(dataset['test_targets']), axis=1)\n",
    "\n",
    "num_data, seq_length, _, num_alphabet = X_train_seq.shape\n",
    "\n",
    "# get validation set from training set\n",
    "valid_frac = 0.2\n",
    "N = len(X_train_seq)\n",
    "split_index = int(N*valid_frac)\n",
    "shuffle = np.random.permutation(N)\n",
    "\n",
    "# put in a dictionary for deepomics\n",
    "train = {'inputs': X_train_seq[shuffle[split_index:]], \n",
    "         'targets': Y_train[shuffle[split_index:]]}\n",
    "valid = {'inputs': X_train_seq[shuffle[:split_index]], \n",
    "         'targets': Y_train[shuffle[:split_index]]}\n",
    "test = {'inputs': X_test_seq, 'targets': Y_test}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, output_shape):\n",
    "\n",
    "    # create model\n",
    "    layer1 = {'layer': 'input', #41\n",
    "            'input_shape': input_shape\n",
    "            }\n",
    "    layer2 = {'layer': 'conv1d',\n",
    "            'num_filters': 96,\n",
    "            'filter_size': input_shape[1]-29,\n",
    "            'norm': 'batch',\n",
    "            'activation': 'relu',\n",
    "            'dropout': 0.3,\n",
    "            'padding': 'VALID',\n",
    "            }\n",
    "    layer3 = {'layer': 'conv1d_residual',\n",
    "            'filter_size': 5,\n",
    "            'function': 'relu',\n",
    "            'dropout_block': 0.1,\n",
    "            'dropout': 0.3,\n",
    "            'mean_pool': 10,\n",
    "            }\n",
    "    layer4 = {'layer': 'conv1d',\n",
    "            'num_filters': 196,\n",
    "            'filter_size': 3,\n",
    "            'norm': 'batch',\n",
    "            'activation': 'relu',\n",
    "            'dropout': 0.5,\n",
    "            'padding': 'VALID',\n",
    "            }\n",
    "    layer5 = {'layer': 'dense',\n",
    "            'num_units': output_shape[1],\n",
    "            'activation': 'sigmoid'\n",
    "            }\n",
    "\n",
    "    model_layers = [layer1, layer2, layer3, layer4, layer5]\n",
    "\n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                  \"optimizer\": \"adam\",\n",
    "                  \"learning_rate\": 0.0003,\n",
    "                  \"l2\": 1e-5,\n",
    "                  #\"label_smoothing\": 0.05,\n",
    "                  #\"l1\": 1e-6,\n",
    "                  }\n",
    "    return model_layers, optimization\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# get shapes of inputs and targets\n",
    "input_shape = list(train['inputs'].shape)\n",
    "input_shape[0] = None\n",
    "output_shape = train['targets'].shape\n",
    "\n",
    "# load model parameters\n",
    "model_layers, optimization = cnn_model(input_shape, output_shape)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(seed=247)\n",
    "nnmodel.build_layers(model_layers, optimization)\n",
    "\n",
    "# compile neural trainer\n",
    "save_path = 'results/trial'\n",
    "param_path = os.path.join(save_path, 'hairpin')\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, save='best', file_path=param_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Network architecture:\n",
      "----------------------------------------------------------------------------\n",
      "layer1: inputs\n",
      "(?, 41, 1, 4)\n",
      "layer2: conv1d_0\n",
      "(?, 30, 1, 96)\n",
      "layer3: conv1d_0_batch\n",
      "(?, 30, 1, 96)\n",
      "layer4: conv1d_0_active\n",
      "(?, 30, 1, 96)\n",
      "layer5: conv1d_0_dropout\n",
      "(?, 30, 1, 96)\n",
      "layer6: conv1d_residual_0_1resid\n",
      "(?, 30, 1, 96)\n",
      "layer7: conv1d_residual_0_1resid_norm\n",
      "(?, 30, 1, 96)\n",
      "layer8: conv1d_residual_0_1resid_active\n",
      "(?, 30, 1, 96)\n",
      "layer9: conv1d_residual_0_dropout1\n",
      "(?, 30, 1, 96)\n",
      "layer10: conv1d_residual_0_2resid\n",
      "(?, 30, 1, 96)\n",
      "layer11: conv1d_residual_0_2resid_norm\n",
      "(?, 30, 1, 96)\n",
      "layer12: conv1d_residual_0_resid_sum\n",
      "(?, 30, 1, 96)\n",
      "layer13: conv1d_residual_0_resid\n",
      "(?, 30, 1, 96)\n",
      "layer14: conv1d_residual_0_meanpool\n",
      "(?, 3, 1, 96)\n",
      "layer15: conv1d_residual_0_dropout\n",
      "(?, 3, 1, 96)\n",
      "layer16: conv1d_1\n",
      "(?, 1, 1, 196)\n",
      "layer17: conv1d_1_batch\n",
      "(?, 1, 1, 196)\n",
      "layer18: conv1d_1_active\n",
      "(?, 1, 1, 196)\n",
      "layer19: conv1d_1_dropout\n",
      "(?, 1, 1, 196)\n",
      "layer20: dense_0\n",
      "(?, 1)\n",
      "layer21: dense_0_bias\n",
      "(?, 1)\n",
      "layer22: output\n",
      "(?, 1)\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# look at the shapes of each layer\n",
    "nnmodel.inspect_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize session\n",
    "sess = utils.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Predictions\n",
    "\n",
    "# calculate activations\n",
    "predictionsoutput = nntrainer.get_activations(sess, test, layer='output')\n",
    "predictionslogits = nntrainer.get_activations(sess, test, layer='dense_0_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstordermut_saliency(X, layer, alphabet, figsize=(15,2)):\n",
    "\n",
    "    ''' requires that deepomics is being used and the appropriate architecture has already been constructed\n",
    "    Must first initialize the session and set best parameters\n",
    "\n",
    "    layer is the activation layer we want to use as a string\n",
    "    figsize is the figure size we want to use'''\n",
    "\n",
    "    #first mutate the sequence\n",
    "    X_mut = mf.mutate(X, X.shape[1], X.shape[3])\n",
    "\n",
    "    #take all the mutations and assign them into a dict for deepomics\n",
    "    mutations = {'inputs': X_mut, 'targets': np.ones((X_mut.shape[0], 1))}\n",
    "    #Get output or logits activations for the mutations\n",
    "    mut_predictions = nntrainer.get_activations(sess, mutations, layer=layer)\n",
    "\n",
    "\n",
    "    #take the WT and put it into a dict for deepomics\n",
    "    WT = {'inputs': X, 'targets': np.ones((X.shape[0], 1))}\n",
    "    #Get output or logits activations for the WT sequence\n",
    "    predictions = nntrainer.get_activations(sess, WT, layer=layer)\n",
    "\n",
    "    #shape the predictions of the mutations into the shape of a heatmap\n",
    "    heat_mut = mut_predictions.reshape(X.shape[1],4).T\n",
    "    \n",
    "    #normalize the heat map rearrangement by minusing it by the true prediction score of that test sequence\n",
    "    norm_heat_mut = heat_mut - predictions[0]\n",
    "    norm_heat_mut = utils.normalize_pwm(norm_heat_mut, factor=4)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    visualize.plot_seq_pos_saliency(np.squeeze(X).T, \n",
    "                                        norm_heat_mut,\n",
    "                                        alphabet=alphabet, \n",
    "                                        nt_width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffanpaul/Eddy Lab/RNA_secstructure/deepomics/utils.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pwm = pwm/MAX\n",
      "/Users/steffanpaul/anaconda/envs/tensorflow/lib/python3.6/site-packages/matplotlib/figure.py:1743: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAACICAYAAAAWA8eRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEVYAABUhAUAQEVYAABUhAUAQPV/5lWJy1FD69IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183baba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort activations\n",
    "import mutagenesis_functions as mf\n",
    "\n",
    "plot_index = np.argsort(predictionsoutput[:,0])[::-1]\n",
    "\n",
    "X = np.expand_dims(test['inputs'][plot_index[0]], axis=0)\n",
    "\n",
    "firstordermut_saliency(X, layer='output', alphabet='rna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffanpaul/Eddy Lab/RNA_secstructure/deepomics/utils.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pwm = pwm/MAX\n",
      "/Users/steffanpaul/anaconda/envs/tensorflow/lib/python3.6/site-packages/matplotlib/figure.py:1743: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAACICAYAAAAWA8eRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEVYAABUhAUAQEVYAABUhAUAQPV/5lWJy1FD69IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11831efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mutagenesis_functions as mf\n",
    "\n",
    "# initialize session\n",
    "sess = utils.initialize_session()\n",
    "\n",
    "plot_index = np.argsort(predictionsoutput[:,0])[::-1]\n",
    "\n",
    "X = np.expand_dims(test['inputs'][plot_index[0]], axis=0)\n",
    "\n",
    "layer = 'output'\n",
    "alphabet = 'rna'\n",
    "figsize = (15,2)\n",
    "\n",
    "#first mutate the sequence\n",
    "X_mut = mf.mutate(X, X.shape[1], X.shape[3])\n",
    "\n",
    "#take all the mutations and assign them into a dict for deepomics\n",
    "mutations = {'inputs': X_mut, 'targets': np.ones((X_mut.shape[0], 1))}\n",
    "#Get output or logits activations for the mutations\n",
    "mut_predictions = nntrainer.get_activations(sess, mutations, layer=layer)\n",
    "\n",
    "\n",
    "#take the WT and put it into a dict for deepomics\n",
    "WT = {'inputs': X, 'targets': np.ones((X.shape[0], 1))}\n",
    "#Get output or logits activations for the WT sequence\n",
    "predictions = nntrainer.get_activations(sess, WT, layer=layer)\n",
    "\n",
    "#shape the predictions of the mutations into the shape of a heatmap\n",
    "heat_mut = mut_predictions.reshape(X.shape[1],4).T\n",
    "\n",
    "#normalize the heat map rearrangement by minusing it by the true prediction score of that test sequence\n",
    "norm_heat_mut = heat_mut - predictions[0]\n",
    "norm_heat_mut = utils.normalize_pwm(norm_heat_mut, factor=4)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "visualize.plot_seq_pos_saliency(np.squeeze(X).T, \n",
    "                                    norm_heat_mut,\n",
    "                                    alphabet=alphabet, \n",
    "                                    nt_width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = nntrainer.get_activations(sess, WT, layer=layer)\n",
    "\n",
    "mut_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
