{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from deepomics import neuralnetwork as nn\n",
    "from deepomics import utils, fit, visualize, saliency\n",
    "import scipy\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../..')\n",
    "import mutagenesisfunctions as mf\n",
    "from Bio import AlignIO\n",
    "import time as time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = '../../../data_rfam/glna_100k_t7.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a69754b31223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../../data_RFAM/glna_100k_t7.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mY_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peter/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peter/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_objects.c:2856)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/_objects.c:2814)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/home/ilan/minonda/conda-bld/h5py_1486190692013/work/h5py/h5f.c:2102)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = '../../../data_rfam/glna_100k_t7.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "#Open data from h5py\n",
    "\n",
    "data_path = '../../../data_RFAM/glna_100k_d7.hdf5'\n",
    "with h5py.File(data_path, 'r') as dataset:\n",
    "    X_data = np.array(dataset['X_data'])\n",
    "    Y_data = np.array(dataset['Y_data'])\n",
    "    \n",
    "numdata, seqlen, _, dims = X_data.shape\n",
    "dims = dims-1\n",
    "\n",
    "#remove gaps from sequences\n",
    "ungapped = True\n",
    "if ungapped:\n",
    "    X_data = X_data[:, :, :, :dims]\n",
    "    \n",
    "# get validation and test set from training set\n",
    "test_frac = 0.3\n",
    "valid_frac = 0.1\n",
    "N = numdata\n",
    "split_1 = int(N*(1-valid_frac-test_frac))\n",
    "split_2 = int(N*(1-test_frac))\n",
    "shuffle = np.random.permutation(N)\n",
    "\n",
    "#set up dictionaries\n",
    "train = {'inputs': X_data[shuffle[:split_1]], \n",
    "         'targets': Y_data[shuffle[:split_1]]}\n",
    "valid = {'inputs': X_data[shuffle[split_1:split_2]], \n",
    "         'targets': Y_data[shuffle[split_1:split_2]]}\n",
    "test = {'inputs': X_data[shuffle[split_2:]], \n",
    "         'targets': Y_data[shuffle[split_2:]]}\n",
    "    \n",
    "print ('Data extraction and dict construction completed in: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simalign_file = '../../../data_RFAM/glnAsim_100k.sto'\n",
    "\n",
    "#Get the full secondary structure and sequence consensus from the emission\n",
    "SS = mf.getSSconsensus(simalign_file)\n",
    "SQ = mf.getSQconsensus(simalign_file)\n",
    "\n",
    "#Get the ungapped sequence and the indices of ungapped nucleotides\n",
    "_, ugSS, ugidx = mf.rm_consensus_gaps(X_data, SS)\n",
    "_, ugSQ, _ = mf.rm_consensus_gaps(X_data, SQ)\n",
    "\n",
    "\n",
    "#Get the sequence and indices of the conserved base pairs\n",
    "bpchars = ['(',')','<','>','{','}']\n",
    "sig_bpchars = ['<','>']\n",
    "bpidx, bpSS, nonbpidx = mf.sigbasepair(SS, bpchars)\n",
    "numbp = len(bpidx)\n",
    "numug = len(ugidx)\n",
    "\n",
    "#Get the bpug information\n",
    "bpugSQ, bpugidx = mf.bpug(ugidx, bpidx, SQ)\n",
    "\n",
    "bpSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ugSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, output_shape):\n",
    "\n",
    "    # create model\n",
    "    layer1 = {'layer': 'input', #41\n",
    "            'input_shape': input_shape\n",
    "            }\n",
    "    layer2 = {'layer': 'conv1d',\n",
    "            'num_filters': 96,\n",
    "            'filter_size': input_shape[1]-29,\n",
    "            'norm': 'batch',\n",
    "            'activation': 'relu',\n",
    "            'dropout': 0.3,\n",
    "            'padding': 'VALID',\n",
    "            }\n",
    "    layer3 = {'layer': 'conv1d_residual',\n",
    "            'filter_size': 5,\n",
    "            'function': 'relu',\n",
    "            'dropout_block': 0.1,\n",
    "            'dropout': 0.3,\n",
    "            'mean_pool': 10,\n",
    "            }\n",
    "    \n",
    "    layer4 = {'layer': 'dense',        # input, conv1d, dense, conv1d_residual, dense_residual, conv1d_transpose,\n",
    "                                    # concat, embedding, variational_normal, variational_softmax, + more\n",
    "          'num_units': 196,\n",
    "          'norm': 'batch',          # if removed, automatically adds bias instead\n",
    "          'activation': 'relu',     # or leaky_relu, prelu, sigmoid, tanh, etc\n",
    "          'dropout': 0.5,           # if removed, default is no dropout\n",
    "             }\n",
    "\n",
    "    \n",
    "    layer5 = {'layer': 'dense',\n",
    "            'num_units': output_shape[1],\n",
    "            'activation': 'sigmoid'\n",
    "            }\n",
    "\n",
    "    model_layers = [layer1, layer2, layer3, layer4, layer5]\n",
    "\n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                  \"optimizer\": \"adam\",\n",
    "                  \"learning_rate\": 0.0003,\n",
    "                  \"l2\": 1e-5,\n",
    "                  #\"label_smoothing\": 0.05,\n",
    "                  #\"l1\": 1e-6,\n",
    "                  }\n",
    "    return model_layers, optimization\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# get shapes of inputs and targets\n",
    "input_shape = list(train['inputs'].shape)\n",
    "input_shape[0] = None\n",
    "output_shape = train['targets'].shape\n",
    "\n",
    "# load model parameters\n",
    "model_layers, optimization = cnn_model(input_shape, output_shape)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(seed=247)\n",
    "nnmodel.build_layers(model_layers, optimization)\n",
    "\n",
    "# compile neural trainer\n",
    "save_path = '../../../results/glnA'\n",
    "param_path = os.path.join(save_path, 'resbind_t7')\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, save='best', file_path=param_path)\n",
    "\n",
    "# look at the shapes of each layer\n",
    "nnmodel.inspect_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize session\n",
    "sess = utils.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "\n",
    "data = {'train': train, 'valid': valid}\n",
    "fit.train_minibatch(sess, nntrainer, data, \n",
    "                    batch_size=100, \n",
    "                    num_epochs=100,\n",
    "                    patience=30, \n",
    "                    verbose=2, \n",
    "                    shuffle=True, \n",
    "                    save_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize session\n",
    "sess.close()\n",
    "sess = utils.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set best parameters\n",
    "nntrainer.set_best_parameters(sess)\n",
    "\n",
    "# test model\n",
    "loss, mean_vals, std_vals = nntrainer.test_model(sess, test, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort activations\n",
    "predictionsoutput = nntrainer.get_activations(sess, test, layer='output')\n",
    "plot_index = np.argsort(predictionsoutput[:,0])[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('Predicted score')\n",
    "plt.xlabel('Sequences ordered by score')\n",
    "plt.plot(range(len(plot_index)), predictionsoutput[plot_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_plots=np.linspace(0,20000,5).astype(int)\n",
    "#num_plots = range(5)\n",
    "for ii in num_plots: \n",
    "\n",
    "    X = np.expand_dims(test['inputs'][plot_index[ii]], axis=0)\n",
    "    \n",
    "    mf.fom_saliency(X, layer='dense_1_bias', alphabet='rna', nntrainer=nntrainer, sess=sess, figsize=(15,1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#num_plots=np.linspace(0,10000,10).astype(int)\n",
    "num_plots = range(int(numdata*test_frac))\n",
    "#for sp, ii in enumerate(num_plots): \n",
    "    \n",
    "def nucpresence(Xdict, ii):\n",
    "    X = np.expand_dims(Xdict['inputs'][plot_index[ii]], axis=0)\n",
    "    nuc_index = np.where(np.sum(X, axis=0)!=0)[0]\n",
    "    nucpos = np.zeros(shape=(1,seqlen))\n",
    "    nucpos[:, nuc_index] = 1.\n",
    "    return nucpos\n",
    "\n",
    "nuc_sequences = [nucpresence(test,ii) for ii in num_plots]\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "sb.heatmap(np.squeeze(nuc_sequences)[:, bpidx].T, cbar=False)\n",
    "plt.ylabel('Conserved Base pairs by covariance')\n",
    "plt.xlabel('Sequence rank number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savepath = 'Arrays/glna_resbindt7_ug_so1k.npy'\n",
    "\n",
    "num_summary = 1000\n",
    "Xdict = test['inputs'][plot_index[:num_summary]]\n",
    "\n",
    "sum_mut2 = mf.som_average_ungapped(Xdict, ungapped_index=ugidx, savepath=savepath, nntrainer=nntrainer, \n",
    "                                sess=sess, progress='off', save=True, layer='dense_1_bias', \n",
    "                               normalize=False, normfactor=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load values\n",
    "savepath = 'Arrays/glna_resbindt7_ug_so1k.npy'\n",
    "sum_mut2 = np.load(savepath)\n",
    "\n",
    "#average the values\n",
    "num_summary = 1000\n",
    "mean_mut2 = sum_mut2/num_summary\n",
    "\n",
    "#Reshape into a holistic tensor organizing the mutations into 4*4 matrices\n",
    "meanhol_mut2 = mean_mut2.reshape(numug,numug,dims,dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize the holistic mutation scores\n",
    "WT_mean = np.mean(nntrainer.get_activations(sess, test, layer='dense_1_bias')[plot_index[:500]])\n",
    "\n",
    "def normalize_mut_hol(hol_mut, WTmean, nntrainer, sess, normfactor=None):\n",
    "    norm_hol_mut = np.copy(hol_mut) - WTmean\n",
    "    for one in range(hol_mut.shape[0]):\n",
    "        for two in range(hol_mut.shape[0]):\n",
    "            norm_hol_mut[one, two] = mf.normalize_hol(hol_mut[one, two], factor=normfactor)\n",
    "    return norm_hol_mut\n",
    "\n",
    "norm_meanhol_mut2 = normalize_mut_hol(meanhol_mut2, WT_mean, nntrainer, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's try something weird\n",
    "bpfilter = np.ones((4,4))*-1\n",
    "for i,j in zip(range(4), range(4)):\n",
    "    bpfilter[i, -(j+1)] = 1.\n",
    "    \n",
    "C = np.sum((norm_meanhol_mut2*bpfilter).reshape(numug,numug,dims*dims), axis=2)\n",
    "C = C - np.mean(C)\n",
    "C = C/np.max(C)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "sb.heatmap(C, xticklabels=bpugSQ, yticklabels=bpugSQ, vmin=0.2, cmap='Reds', linewidth=0.01)\n",
    "plt.title('Base Pair score for the ungapped consensus regions given by infernal')\n",
    "plt.xlabel('Ungapped nucleotides: pos 1')\n",
    "plt.ylabel('Ungapped nucleotides: pos 2')\n",
    "plt.subplot(1,2,2)\n",
    "sb.heatmap(C[bpugidx][:, bpugidx], xticklabels=bpSS, yticklabels=bpSS, vmin=0.2, cmap='Reds', linewidth=0.01)\n",
    "plt.title('Base Pair score for the base paired consensus regions given by infernal')\n",
    "plt.xlabel('Base Paired nucleotides: pos 1')\n",
    "plt.ylabel('Base Paired nucleotides: pos 2')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bpugSQ = ['.' for i in range(len(ugidx))]\n",
    "bpugidx = []\n",
    "for i, ix in enumerate(ugidx):\n",
    "    if ix in bpidx:\n",
    "        bpugSQ[i] = SQ[ix]\n",
    "        bpugidx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C[bpugidx][:, bpugidx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
