{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, h5py, os\n",
    "sys.path.append('../../../..')\n",
    "import mutagenesisfunctions as mf\n",
    "import time as time\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(274)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ALL OF THESE SEQUENCES ARE IN THEIR IDX FORM, NOT HOTPLOT\n",
    "#sequence generator function\n",
    "def randomsequence(N, maxsize, sample=False):\n",
    "    if sample:\n",
    "        seq_sizes = np.random.randint(1, maxsize, size=N)\n",
    "    else:\n",
    "        seq_sizes = (np.ones((N))*maxsize).astype(int)\n",
    "        \n",
    "    seq_idxs = []\n",
    "    for seq_size in seq_sizes:\n",
    "        seq_idx = np.random.randint(0,4, size=seq_size)\n",
    "        seq_idxs.append(list(seq_idx))\n",
    "    return (seq_idxs)\n",
    "\n",
    "#stem region generator\n",
    "def stemregion(N, maxsize, sample=False):\n",
    "    stem1 = randomsequence(N, maxsize, sample=sample)\n",
    "    #generate reverse complement of stem1\n",
    "    bpref = {0:3, 1:2, 2:1, 3:0}\n",
    "    stem2 = []\n",
    "    for s in stem1:\n",
    "        seq_idx = [bpref[n] for n in s]\n",
    "        stem2.append(seq_idx[::-1])\n",
    "    \n",
    "    return (stem1, stem2)\n",
    "\n",
    "#CONVERT IDX TO ONEHOT\n",
    "def onehot(sequence):\n",
    "    length = len(sequence)\n",
    "    onehotseq = np.zeros((length, 4))\n",
    "    for i,s in enumerate(sequence):\n",
    "        onehotseq[i, s] = 1.\n",
    "    return (onehotseq.astype(np.float32))\n",
    "\n",
    "#SAVE THE DATA\n",
    "def savehdf5(hdf5path, X_data, Y_data):\n",
    "    with h5py.File(hdf5path, 'w') as f:\n",
    "        f.create_dataset('X_data', data=X_data.astype(np.float32), compression='gzip')\n",
    "        f.create_dataset('Y_data', data=Y_data.astype(np.float32), compression='gzip')\n",
    "    print ('Saving data to %s'%(hdf5path))\n",
    "    \n",
    "#OPEN THE DATA\n",
    "def openhdf5(hdf5path):\n",
    "    with h5py.File(hdf5path, 'r') as dataset:\n",
    "        X_data = np.array(dataset['X_data'])\n",
    "        Y_data = np.array(dataset['Y_data'])\n",
    "    return (X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SHUFFLE THE XPOS SEQUENCES TO RANDOM BUNCHES\n",
    "def seq_bunchshuffle(Xpos, numdata, seqlen, bunchsize=(10, 75), numbunches=None):\n",
    "\n",
    "    if bunchsize:\n",
    "        #n = the number of bunches per sequence\n",
    "        smallbunch, largebunch = bunchsize\n",
    "        n_upper = seqlen//smallbunch\n",
    "        n_lower = seqlen//largebunch\n",
    "    if numbunches:\n",
    "        n_lower, n_upper = numbunches\n",
    "\n",
    "    Xshuffle = np.zeros((np.shape(Xpos)))\n",
    "    ns = []\n",
    "    for seq in range(numdata):\n",
    "        Xcopy = np.copy(Xpos[seq])\n",
    "\n",
    "        n = np.random.randint(n_lower, n_upper)\n",
    "\n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        randidx = np.random.permutation(n)\n",
    "        for i in range(n):\n",
    "            idx = randidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            Xshuffle[seq, start:start+space, :] = Xcopy[bunchidx[idx]:bunchidx[idx+1], :]\n",
    "            start = start + space\n",
    "            \n",
    "    return (Xshuffle)\n",
    "\n",
    "\n",
    "#SHUFFLE THE XPOS SEQUENCES TO RANDOM BUNCHES AND DISTRIBUTE THEM BETWEEN EACHOTHER\n",
    "def interseq_bunchshuffle(Xpos, numdata, seqlen, numbunches=4):\n",
    "\n",
    "    Xshuffle = np.zeros((np.shape(Xpos)))\n",
    "    n = numbunches\n",
    "    #ns = []\n",
    "    \n",
    "    #Create the bunch reservoir\n",
    "    bunch_res = [[] for i in range(n)]\n",
    "    for seq in range(numdata):\n",
    "        Xcopy = np.copy(Xpos[seq])\n",
    "\n",
    "\n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        seqidx = np.arange(n)\n",
    "        for i in range(n):\n",
    "            idx = seqidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            bunch_res[i].append(Xcopy[bunchidx[idx]:bunchidx[idx+1], :])\n",
    "            start = start + space\n",
    "    \n",
    "    #shuffle up the order\n",
    "    bunch_shuffled = [np.random.permutation(bunch_res[i]) for i in range(n)]\n",
    "    \n",
    "    \n",
    "    #stitch them back together\n",
    "    for seq in range(numdata):\n",
    "        \n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        seqidx = np.arange(n)\n",
    "        for i in range(n):\n",
    "            idx = seqidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            \n",
    "            Xshuffle[seq, start:start+space, :] = bunch_shuffled[i][seq]\n",
    "            start = start + space\n",
    "    return (Xshuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pseudoknot Generation\n",
    "\n",
    "We will model a simple pseudoknot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildpk(stemsize, loopsize, numstems=2, numloops=5):\n",
    "    '''\n",
    "    Returns a list of integers corresponding to \n",
    "    nucleotide indices.\n",
    "    '''\n",
    "    loops = [randomsequence(1,loopsize)[0] for l in range(numloops)]\n",
    "\n",
    "    stem1s = []\n",
    "    stem2s = []\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    stems = np.vstack([stem1s[0], stem1s[1], stem2s[0], stem2s[1]])\n",
    "\n",
    "    #assemble\n",
    "    pk_idx = []\n",
    "    for ii in range(numloops):\n",
    "        pk_idx=pk_idx + loops[ii]\n",
    "        if ii <= len(stems)-1:\n",
    "            pk_idx=pk_idx+list(stems[ii])\n",
    "    return(pk_idx)\n",
    "\n",
    "def negpk(X_pos):\n",
    "    numdata, seqlen, _ = X_pos.shape\n",
    "    firsthalf = X_pos[:, :seqlen//2, :]\n",
    "    secondhalf = X_pos[:, seqlen//2:, :]\n",
    "    shuffle1 = np.random.permutation(firsthalf)\n",
    "    shuffle2 = np.random.permutation(secondhalf)\n",
    "    X_neg = np.concatenate((shuffle1, shuffle2), axis=1)\n",
    "    return (X_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PK for transfer learning tests - hairpin + pseudoknot\n",
    "\n",
    "We want to simulate a more complicated RNA to test transfer learning.\n",
    "\n",
    "The sequence will have 6 binding regions with regions binding in the following pattern:\n",
    "- 1-3\n",
    "- 2-6\n",
    "- 4-5\n",
    "\n",
    "Where 1-3 and 2-6 comprise the pseudoknot and 4-5 are the hairpin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Second pkhp made. More simple structure as suggested by Peter. Consists of two \n",
    "nested hairpins, with a non-nested binding region in their inner loops.\n",
    "This will have to take in different sizes of stemsize and loopsize \n",
    "as everything is not equal.\n",
    "'''\n",
    "stemsizes = [5,5,3]\n",
    "loopsizes = [5,2,2,10,2,2,5]\n",
    "def build_pkhp(stemsizes=stemsizes, loopsizes=loopsizes, numstems=3, numloops=7):\n",
    "    loops = [randomsequence(1,ls)[0] for ls in loopsizes]\n",
    "    \n",
    "    stem1s = [] #The first binding region of each stem\n",
    "    stem2s = [] #The second binding region of each stem\n",
    "    for sts in stemsizes:\n",
    "        stem1, stem2 = stemregion(1, sts)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    #Add binding regions in the order of their place in the sequence\n",
    "    #print (stem1s[0])\n",
    "    stems = [stem1s[0], stem1s[2], stem2s[0], stem1s[1], stem2s[2], stem2s[1]]\n",
    "\n",
    "    #assemble\n",
    "    pk_idx = []\n",
    "    for ii in range(numloops):\n",
    "        pk_idx=pk_idx + loops[ii]\n",
    "        try:\n",
    "            pk_idx=pk_idx+list(stems[ii])\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return(pk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "np.random.seed(23)\n",
    "#stemsize = 6\n",
    "#numstems = 3\n",
    "#loopsize = 5\n",
    "numloops = 7\n",
    "num = 50000\n",
    "stemsizes = [5,5,3]\n",
    "loopsizes = [5,2,2,10,2,2,5]\n",
    "seqlen = 2*sum(stemsizes)+sum(loopsizes)\n",
    "#seqlen = stemsize*(2*numstems) + loopsize*numloops\n",
    "\n",
    "datatype = 5\n",
    "\n",
    "pkbounds = [[12,15], [39,42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 0, 1, 2, 3, 2, 2, 1, 3, 0, 3, 1, 1, 0, 1, 0, 0, 2, 1, 1, 0, 3, 3, 2, 1, 3, 2, 3, 1, 0, 1, 1, 3, 3, 3, 0, 2, 3, 3, 2, 2, 1, 1, 3, 0, 0, 0, 2, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#GENERATE THE POSITIVE SEQUENCES\n",
    "\n",
    "#for pkhp\n",
    "X_pos_pkhp = np.asarray([onehot(build_pkhp(stemsizes=stemsizes, loopsizes=loopsizes)) for r in range(num)])\n",
    "\n",
    "#for hp - make a copy of pkhp and insert rand seq into pk regions\n",
    "X_pos_hp = np.copy(X_pos_pkhp)\n",
    "X_rand = np.asarray([onehot(randomsequence(1, maxsize=seqlen)[0]) for n in range(num)]) #random sequences\n",
    "#for n in range(num): #Insert randomness .. into the copies sequences\n",
    "\n",
    "for bnd in pkbounds:\n",
    "    X_pos_hp[:, bnd[0]:bnd[1], :] = X_rand[:, bnd[0]:bnd[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERATE THE NEGATIVE SEQUENCES (DATA 1: BOTH AS WELL SHUFFLED COPIES)\n",
    "\n",
    "if datatype == 1:\n",
    "\n",
    "    X_neg_pkhp = seq_bunchshuffle(X_pos_pkhp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "\n",
    "    X_neg_hp = seq_bunchshuffle(X_pos_hp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "\n",
    "#(DATA 2: PKHP NEGATIVE SEQUENCES JUST A COPY OF HP)\n",
    "\n",
    "if datatype == 2:\n",
    "    \n",
    "    X_neg_pkhp = np.copy(X_pos_hp)\n",
    "\n",
    "    X_neg_hp = seq_bunchshuffle(X_pos_hp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "    \n",
    "#(DATA 3: BOTH AS INTERSEQ SHUFFLED COPIES)\n",
    "\n",
    "if datatype == 5 or datatype ==3:\n",
    "    \n",
    "    X_neg_pkhp = interseq_bunchshuffle(X_pos_pkhp, num, seqlen)\n",
    "\n",
    "    X_neg_hp = interseq_bunchshuffle(X_pos_hp, num, seqlen)\n",
    "    \n",
    "#(DATA 4+5: PKHP NEGATIVE SEQUENCES JUST A COPY OF HP BUT HP NEGS A INTERSEQ SHUFFLED SET)\n",
    "\n",
    "if datatype == 6 or datatype ==4:\n",
    "    \n",
    "    X_neg_pkhp = np.copy(X_pos_hp)\n",
    "\n",
    "    X_neg_hp = interseq_bunchshuffle(X_pos_hp, num, seqlen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERATE TWO ARRAYS WITH YLABELS FOR POS AND NEG FOR EASY INDEXING\n",
    "\n",
    "Y_pos = np.ones((num, 1))\n",
    "Y_neg = np.zeros((num, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data: 1.71s\n"
     ]
    }
   ],
   "source": [
    "#PACKAGE THEM INTO A FILE\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "#Save dictionaries into h5py files\n",
    "hdf5path = '../../../data_toypk/toypkhp_50_d%0.f.hdf5'%(datatype)\n",
    "with h5py.File(hdf5path, 'w') as f:\n",
    "    f.create_dataset('X_pos_pkhp', data=X_pos_pkhp.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('X_neg_pkhp', data=X_neg_pkhp.astype(np.float32), compression='gzip')\n",
    "    \n",
    "    f.create_dataset('X_pos_hp', data=X_pos_hp.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('X_neg_hp', data=X_neg_hp.astype(np.float32), compression='gzip')\n",
    "    \n",
    "    f.create_dataset('Y_pos', data=Y_pos.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('Y_neg', data=Y_neg.astype(np.float32), compression='gzip')\n",
    "\n",
    "print ('Saving data: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data_toypk/toypkhp_50_d4.hdf5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "np.random.seed(25)\n",
    "stemsize = 2\n",
    "numstems = 1\n",
    "loopsize = 2\n",
    "numloops = 3\n",
    "num = 5\n",
    "seqlen = stemsize*(2*numstems) + loopsize*numloops\n",
    "\n",
    "datatype = 4\n",
    "\n",
    "#hpstart, hpend = (37,54)\n",
    "X_pos_pkhp = np.asarray([onehot(build_pkhp(stemsize=stemsize, loopsize=loopsize)) for r in range(num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 44, 37, 39, 48])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos_pkhp.shape\n",
    "np.sum(np.argmax(X_pos_pkhp, axis=2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 17, 15, 16, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = interseq_bunchshuffle(X_pos_pkhp, seqlen, num)\n",
    "\n",
    "np.sum(np.argmax(t, axis=2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
