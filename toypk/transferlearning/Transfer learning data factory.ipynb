{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, h5py, os\n",
    "sys.path.append('../../../..')\n",
    "import mutagenesisfunctions as mf\n",
    "import time as time\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(274)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ALL OF THESE SEQUENCES ARE IN THEIR IDX FORM, NOT HOTPLOT\n",
    "#sequence generator function\n",
    "def randomsequence(N, maxsize, sample=False):\n",
    "    if sample:\n",
    "        seq_sizes = np.random.randint(1, maxsize, size=N)\n",
    "    else:\n",
    "        seq_sizes = (np.ones((N))*maxsize).astype(int)\n",
    "        \n",
    "    seq_idxs = []\n",
    "    for seq_size in seq_sizes:\n",
    "        seq_idx = np.random.randint(0,4, size=seq_size)\n",
    "        seq_idxs.append(list(seq_idx))\n",
    "    return (seq_idxs)\n",
    "\n",
    "#stem region generator\n",
    "def stemregion(N, maxsize, sample=False):\n",
    "    stem1 = randomsequence(N, maxsize, sample=sample)\n",
    "    #generate reverse complement of stem1\n",
    "    bpref = {0:3, 1:2, 2:1, 3:0}\n",
    "    stem2 = []\n",
    "    for s in stem1:\n",
    "        seq_idx = [bpref[n] for n in s]\n",
    "        stem2.append(seq_idx[::-1])\n",
    "    \n",
    "    return (stem1, stem2)\n",
    "\n",
    "#CONVERT IDX TO ONEHOT\n",
    "def onehot(sequence):\n",
    "    length = len(sequence)\n",
    "    onehotseq = np.zeros((length, 4))\n",
    "    for i,s in enumerate(sequence):\n",
    "        onehotseq[i, s] = 1.\n",
    "    return (onehotseq.astype(np.float32))\n",
    "\n",
    "#SAVE THE DATA\n",
    "def savehdf5(hdf5path, X_data, Y_data):\n",
    "    with h5py.File(hdf5path, 'w') as f:\n",
    "        f.create_dataset('X_data', data=X_data.astype(np.float32), compression='gzip')\n",
    "        f.create_dataset('Y_data', data=Y_data.astype(np.float32), compression='gzip')\n",
    "    print ('Saving data to %s'%(hdf5path))\n",
    "    \n",
    "#OPEN THE DATA\n",
    "def openhdf5(hdf5path):\n",
    "    with h5py.File(hdf5path, 'r') as dataset:\n",
    "        X_data = np.array(dataset['X_data'])\n",
    "        Y_data = np.array(dataset['Y_data'])\n",
    "    return (X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SHUFFLE THE XPOS SEQUENCES TO RANDOM BUNCHES\n",
    "def seq_bunchshuffle(Xpos, numdata, seqlen, bunchsize=(10, 75), numbunches=None):\n",
    "\n",
    "    if bunchsize:\n",
    "        #n = the number of bunches per sequence\n",
    "        smallbunch, largebunch = bunchsize\n",
    "        n_upper = seqlen//smallbunch\n",
    "        n_lower = seqlen//largebunch\n",
    "    if numbunches:\n",
    "        n_lower, n_upper = numbunches\n",
    "\n",
    "    Xshuffle = np.zeros((np.shape(Xpos)))\n",
    "    ns = []\n",
    "    for seq in range(numdata):\n",
    "        Xcopy = np.copy(Xpos[seq])\n",
    "\n",
    "        n = np.random.randint(n_lower, n_upper)\n",
    "\n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        randidx = np.random.permutation(n)\n",
    "        for i in range(n):\n",
    "            idx = randidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            Xshuffle[seq, start:start+space, :] = Xcopy[bunchidx[idx]:bunchidx[idx+1], :]\n",
    "            start = start + space\n",
    "            \n",
    "    return (Xshuffle)\n",
    "\n",
    "\n",
    "#SHUFFLE THE XPOS SEQUENCES TO RANDOM BUNCHES AND DISTRIBUTE THEM BETWEEN EACHOTHER\n",
    "def interseq_bunchshuffle(Xpos, seqlen, numdata, numbunches=4):\n",
    "\n",
    "    Xshuffle = np.zeros((np.shape(Xpos)))\n",
    "    n = numbunches\n",
    "    #ns = []\n",
    "    \n",
    "    #Create the bunch reservoir\n",
    "    bunch_res = [[] for i in range(n)]\n",
    "    for seq in range(numdata):\n",
    "        Xcopy = np.copy(Xpos[seq])\n",
    "\n",
    "\n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        seqidx = np.arange(n)\n",
    "        for i in range(n):\n",
    "            idx = seqidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            bunch_res[i].append(Xcopy[bunchidx[idx]:bunchidx[idx+1], :])\n",
    "            start = start + space\n",
    "    \n",
    "    #shuffle up the order\n",
    "    bunch_shuffled = [np.random.permutation(bunch_res[i]) for i in range(n)]\n",
    "    \n",
    "    \n",
    "    #stitch them back together\n",
    "    for seq in range(numdata):\n",
    "        \n",
    "        bunchidx = [i*(seqlen//n) for i in range(n)]\n",
    "        bunchidx.append(seqlen)\n",
    "\n",
    "        start=0\n",
    "        seqidx = np.arange(n)\n",
    "        for i in range(n):\n",
    "            idx = seqidx[i]\n",
    "            space = bunchidx[idx+1]-bunchidx[idx]\n",
    "            #Note this is without the pseudo dimension for deepomics\n",
    "            \n",
    "            Xshuffle[seq, start:start+space, :] = bunch_shuffled[i][seq]\n",
    "            \n",
    "            #bunch_res[i].append(Xcopy[bunchidx[idx]:bunchidx[idx+1], :])\n",
    "            start = start + space\n",
    "    return (Xshuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pseudoknot Generation\n",
    "\n",
    "We will model a simple pseudoknot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildpk(stemsize, loopsize, numstems=2, numloops=5):\n",
    "    loops = [randomsequence(1,loopsize)[0] for l in range(numloops)]\n",
    "\n",
    "    stem1s = []\n",
    "    stem2s = []\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    stems = np.vstack([stem1s[0], stem1s[1], stem2s[0], stem2s[1]])\n",
    "\n",
    "    #assemble\n",
    "    pk_idx = []\n",
    "    for ii in range(numloops):\n",
    "        pk_idx=pk_idx + loops[ii]\n",
    "        if ii <= len(stems)-1:\n",
    "            pk_idx=pk_idx+list(stems[ii])\n",
    "    return(pk_idx)\n",
    "\n",
    "def negpk(X_pos):\n",
    "    numdata, seqlen, _ = X_pos.shape\n",
    "    firsthalf = X_pos[:, :seqlen//2, :]\n",
    "    secondhalf = X_pos[:, seqlen//2:, :]\n",
    "    shuffle1 = np.random.permutation(firsthalf)\n",
    "    shuffle2 = np.random.permutation(secondhalf)\n",
    "    X_neg = np.concatenate((shuffle1, shuffle2), axis=1)\n",
    "    return (X_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PK for transfer learning tests - hairpin + pseudoknot\n",
    "\n",
    "We want to simulate a more complicated RNA to test transfer learning.\n",
    "\n",
    "The sequence will have 6 binding regions with regions binding in the following pattern:\n",
    "- 1-3\n",
    "- 2-6\n",
    "- 4-5\n",
    "\n",
    "Where 1-3 and 2-6 comprise the pseudoknot and 4-5 are the hairpin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to build this more complicated pseudoknot (consult notes for structure)\n",
    "def build_pkhp(stemsize=6, loopsize=5, numstems=3, numloops=7):\n",
    "    loops = [randomsequence(1,loopsize)[0] for l in range(numloops)]\n",
    "    \n",
    "    stem1s = [] #The first binding region of each stem\n",
    "    stem2s = [] #The second binding region of each stem\n",
    "    for s in range(numstems):\n",
    "        stem1, stem2 = stemregion(1, stemsize)\n",
    "        stem1s.append(stem1[0])\n",
    "        stem2s.append(stem2[0])\n",
    "    #Add binding regions in the order of their place in the sequence\n",
    "    stems = np.vstack([stem1s[0], stem1s[1], stem2s[0], stem1s[2], stem2s[2], stem2s[1]])\n",
    "\n",
    "    #assemble\n",
    "    pk_idx = []\n",
    "    for ii in range(numloops):\n",
    "        pk_idx=pk_idx + loops[ii]\n",
    "        if ii <= len(stems)-1:\n",
    "            pk_idx=pk_idx+list(stems[ii])\n",
    "    return(pk_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters\n",
    "np.random.seed(23)\n",
    "stemsize = 6\n",
    "numstems = 3\n",
    "loopsize = 5\n",
    "numloops = 7\n",
    "num = 50000\n",
    "seqlen = stemsize*(2*numstems) + loopsize*numloops\n",
    "\n",
    "datatype = 4\n",
    "\n",
    "hpstart, hpend = (37,54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GENERATE THE POSITIVE SEQUENCES\n",
    "\n",
    "#for pkhp\n",
    "X_pos_pkhp = np.asarray([onehot(build_pkhp(stemsize=stemsize, loopsize=loopsize)) for r in range(num)])\n",
    "\n",
    "#for hp\n",
    "X_pos_hp = np.asarray([onehot(randomsequence(1, maxsize=seqlen)[0]) for n in range(num)]) #random sequences\n",
    "for n in range(num): #Insert the hairpin () into the random sequences\n",
    "    X_pos_hp[n, hpstart:hpend, :] = X_pos_pkhp[n, hpstart:hpend, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GENERATE THE NEGATIVE SEQUENCES (DATA 1: BOTH AS WELL SHUFFLED COPIES)\n",
    "\n",
    "if datatype == 1:\n",
    "\n",
    "    X_neg_pkhp = seq_bunchshuffle(X_pos_pkhp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "\n",
    "    X_neg_hp = seq_bunchshuffle(X_pos_hp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "\n",
    "#(DATA 2: PKHP NEGATIVE SEQUENCES JUST A COPY OF HP)\n",
    "\n",
    "if datatype == 2:\n",
    "    \n",
    "    X_neg_pkhp = np.copy(X_pos_hp)\n",
    "\n",
    "    X_neg_hp = seq_bunchshuffle(X_pos_hp, num, seqlen, bunchsize=None, numbunches=(2,4))\n",
    "    \n",
    "#(DATA 3: BOTH AS INTERSEQ SHUFFLED COPIES)\n",
    "\n",
    "if datatype == 3:\n",
    "    \n",
    "    X_neg_pkhp = interseq_bunchshuffle(X_pos_pkhp, num, seqlen)\n",
    "\n",
    "    X_neg_hp = interseq_bunchshuffle(X_pos_hp, num, seqlen)\n",
    "    \n",
    "#(DATA 4: PKHP NEGATIVE SEQUENCES JUST A COPY OF HP BUT HP NEGS A INTERSEQ SHUFFLED SET)\n",
    "\n",
    "if datatype == 4:\n",
    "    \n",
    "    X_neg_pkhp = np.copy(X_pos_hp)\n",
    "\n",
    "    X_neg_hp = interseq_bunchshuffle(X_pos_hp, num, seqlen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERATE TWO ARRAYS WITH YLABELS FOR POS AND NEG FOR EASY INDEXING\n",
    "\n",
    "Y_pos = np.ones((num, 1))\n",
    "Y_neg = np.zeros((num, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data: 1.53s\n"
     ]
    }
   ],
   "source": [
    "#PACKAGE THEM INTO A FILE\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "#Save dictionaries into h5py files\n",
    "hdf5path = '../../../data_toypk/toypkhp_50_d%0.f.hdf5'%(datatype)\n",
    "with h5py.File(hdf5path, 'w') as f:\n",
    "    f.create_dataset('X_pos_pkhp', data=X_pos_pkhp.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('X_neg_pkhp', data=X_neg_pkhp.astype(np.float32), compression='gzip')\n",
    "    \n",
    "    f.create_dataset('X_pos_hp', data=X_pos_hp.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('X_neg_hp', data=X_neg_hp.astype(np.float32), compression='gzip')\n",
    "    \n",
    "    f.create_dataset('Y_pos', data=Y_pos.astype(np.float32), compression='gzip')\n",
    "    f.create_dataset('Y_neg', data=Y_neg.astype(np.float32), compression='gzip')\n",
    "\n",
    "print ('Saving data: ' + mf.sectotime(time.time() - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../data_toypk/toypkhp_50_d4.hdf5'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
