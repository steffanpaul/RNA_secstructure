{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------  trna  ---------------\n",
      "Sequences trained on:  140000.0\n",
      "Data extraction and dict construction completed in: 6.12s\n",
      "loading model from:  ../../results/trainsize/resbind_trna_tp70_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_trna_tp70_best.ckpt\n",
      "  test  loss:\t\t0.01359\n",
      "  test  accuracy:\t0.99950+/-0.00000\n",
      "  test  auc-roc:\t1.00000+/-0.00000\n",
      "  test  auc-pr:\t\t1.00000+/-0.00000\n",
      "Sequences trained on:  100000.0\n",
      "Data extraction and dict construction completed in: 5.87s\n",
      "loading model from:  ../../results/trainsize/resbind_trna_tp50_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_trna_tp50_best.ckpt\n",
      "  test  loss:\t\t0.01563\n",
      "  test  accuracy:\t0.99875+/-0.00000\n",
      "  test  auc-roc:\t0.99996+/-0.00000\n",
      "  test  auc-pr:\t\t0.99997+/-0.00000\n",
      "Sequences trained on:  60000.0\n",
      "Data extraction and dict construction completed in: 6.09s\n",
      "loading model from:  ../../results/trainsize/resbind_trna_tp30_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_trna_tp30_best.ckpt\n",
      "  test  loss:\t\t0.01859\n",
      "  test  accuracy:\t0.99752+/-0.00000\n",
      "  test  auc-roc:\t0.99991+/-0.00000\n",
      "  test  auc-pr:\t\t0.99985+/-0.00000\n",
      "Sequences trained on:  20000.0\n",
      "Data extraction and dict construction completed in: 5.79s\n",
      "loading model from:  ../../results/trainsize/resbind_trna_tp10_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_trna_tp10_best.ckpt\n",
      "  test  loss:\t\t0.02610\n",
      "  test  accuracy:\t0.99576+/-0.00000\n",
      "  test  auc-roc:\t0.99984+/-0.00000\n",
      "  test  auc-pr:\t\t0.99981+/-0.00000\n",
      "----------------  riboswitch  ---------------\n",
      "Sequences trained on:  140000.0\n",
      "Data extraction and dict construction completed in: 8.79s\n",
      "loading model from:  ../../results/trainsize/resbind_riboswitch_tp70_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_riboswitch_tp70_best.ckpt\n",
      "  test  loss:\t\t0.02166\n",
      "  test  accuracy:\t0.99725+/-0.00000\n",
      "  test  auc-roc:\t0.99993+/-0.00000\n",
      "  test  auc-pr:\t\t0.99993+/-0.00000\n",
      "Sequences trained on:  100000.0\n",
      "Data extraction and dict construction completed in: 9.86s\n",
      "loading model from:  ../../results/trainsize/resbind_riboswitch_tp50_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_riboswitch_tp50_best.ckpt\n",
      "  test  loss:\t\t0.02234\n",
      "  test  accuracy:\t0.99785+/-0.00000\n",
      "  test  auc-roc:\t0.99997+/-0.00000\n",
      "  test  auc-pr:\t\t0.99997+/-0.00000\n",
      "Sequences trained on:  60000.0\n",
      "Data extraction and dict construction completed in: 8.7s\n",
      "loading model from:  ../../results/trainsize/resbind_riboswitch_tp30_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_riboswitch_tp30_best.ckpt\n",
      "  test  loss:\t\t0.02893\n",
      "  test  accuracy:\t0.99662+/-0.00000\n",
      "  test  auc-roc:\t0.99992+/-0.00000\n",
      "  test  auc-pr:\t\t0.99991+/-0.00000\n",
      "Sequences trained on:  20000.0\n",
      "Data extraction and dict construction completed in: 9.66s\n",
      "loading model from:  ../../results/trainsize/resbind_riboswitch_tp10_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_riboswitch_tp10_best.ckpt\n",
      "  test  loss:\t\t0.04396\n",
      "  test  accuracy:\t0.98931+/-0.00000\n",
      "  test  auc-roc:\t0.99943+/-0.00000\n",
      "  test  auc-pr:\t\t0.99941+/-0.00000\n",
      "----------------  glna  ---------------\n",
      "Sequences trained on:  140000.0\n",
      "Data extraction and dict construction completed in: 10.96s\n",
      "loading model from:  ../../results/trainsize/resbind_glna_tp70_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_glna_tp70_best.ckpt\n",
      "  test  loss:\t\t0.00379\n",
      "  test  accuracy:\t1.00000+/-0.00000\n",
      "  test  auc-roc:\t1.00000+/-0.00000\n",
      "  test  auc-pr:\t\t1.00000+/-0.00000\n",
      "Sequences trained on:  100000.0\n",
      "Data extraction and dict construction completed in: 10.77s\n",
      "loading model from:  ../../results/trainsize/resbind_glna_tp50_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_glna_tp50_best.ckpt\n",
      "  test  loss:\t\t0.00464\n",
      "  test  accuracy:\t0.99989+/-0.00000\n",
      "  test  auc-roc:\t1.00000+/-0.00000\n",
      "  test  auc-pr:\t\t1.00000+/-0.00000\n",
      "Sequences trained on:  60000.0\n",
      "Data extraction and dict construction completed in: 10.69s\n",
      "loading model from:  ../../results/trainsize/resbind_glna_tp30_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_glna_tp30_best.ckpt\n",
      "  test  loss:\t\t0.00665\n",
      "  test  accuracy:\t0.99973+/-0.00000\n",
      "  test  auc-roc:\t0.99999+/-0.00000\n",
      "  test  auc-pr:\t\t0.99999+/-0.00000\n",
      "Sequences trained on:  20000.0\n",
      "Data extraction and dict construction completed in: 10.72s\n",
      "loading model from:  ../../results/trainsize/resbind_glna_tp10_best.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../results/trainsize/resbind_glna_tp10_best.ckpt\n",
      "  test  loss:\t\t0.00718\n",
      "  test  accuracy:\t0.99963+/-0.00000\n",
      "  test  auc-roc:\t0.99999+/-0.00000\n",
      "  test  auc-pr:\t\t0.99999+/-0.00000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import mutagenesisfunctions as mf\n",
    "import helper \n",
    "from deepomics import neuralnetwork as nn\n",
    "from deepomics import utils, fit, visualize, saliency\n",
    "\n",
    "from Bio import AlignIO\n",
    "import time as time\n",
    "import pandas as pd\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "'''DEFINE ACTIONS'''\n",
    "TRAIN = False\n",
    "TEST = False\n",
    "WRITE = False\n",
    "FOM = False\n",
    "SOMCALC = False\n",
    "SOMVIS = False\n",
    "\n",
    "if '--train' in sys.argv:\n",
    "    TRAIN = True\n",
    "if '--test' in sys.argv:\n",
    "    TEST = True\n",
    "if '--write' in sys.argv:\n",
    "    WRITE = True\n",
    "if '--fom' in sys.argv:\n",
    "    FOM = True\n",
    "if '--somcalc' in sys.argv:\n",
    "    SOMCALC = True\n",
    "if '--somvis' in sys.argv:\n",
    "    SOMVIS = True\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "'''DEFINE LOOP'''\n",
    "trials = ['trna', 'riboswitch', 'glna']\n",
    "trainportion_list = [0.7, 0.5, 0.3, 0.1] #0.7 is the original trainportion we've been working with\n",
    "\n",
    "datafiles = {'glna': ['glna_100k_d8.hdf5', '../../data_RFAM/glnAsim_100k.sto'], \n",
    "              'trna': ['trna_100k_d4.hdf5', '../../data_RFAM/trnasim_100k.sto'],\n",
    "              'riboswitch': ['riboswitch_100k_d4.hdf5', '../../data_RFAM/riboswitch_100k.sto'],}\n",
    "\n",
    "exp = 'trainsize'  #for the params folder\n",
    "\n",
    "\n",
    "img_folder = 'Images'\n",
    "\n",
    "for t in trials:\n",
    "    print ('----------------  %s  ---------------'%(t))\n",
    "    for trainportion in trainportion_list:\n",
    "        print ('Sequences trained on: ', trainportion*200000)\n",
    "\n",
    "        \n",
    "        '''OPEN DATA'''\n",
    "\n",
    "        starttime = time.time()\n",
    "\n",
    "        #Open data from h5py\n",
    "        exp_data = 'data_background'\n",
    "        filename = '%s_100k_sh%.0f.hdf5'%(t, 0.25*100) #We're importing the data that we originally baselined against 75:25 profile:shuffle\n",
    "        data_path = os.path.join('../..', exp_data, filename)\n",
    "        with h5py.File(data_path, 'r') as dataset:\n",
    "            X_data = np.array(dataset['X_data'])\n",
    "            Y_data = np.array(dataset['Y_data'])\n",
    "\n",
    "        numdata, seqlen, _, dims = X_data.shape\n",
    "        dims = dims-1\n",
    "\n",
    "        #remove gaps from sequences\n",
    "        ungapped = True\n",
    "        if ungapped:\n",
    "            X_data = X_data[:, :, :, :dims]\n",
    "\n",
    "        # get validation and test set from training set\n",
    "        train_frac = trainportion\n",
    "        valid_frac = 0.1\n",
    "        test_frac = 1-trainportion-valid_frac\n",
    "        N = numdata\n",
    "        split_1 = int(N*(1-valid_frac-test_frac))\n",
    "        split_2 = int(N*(1-test_frac))\n",
    "        shuffle = np.random.permutation(N)\n",
    "\n",
    "        #set up dictionaries\n",
    "        train = {'inputs': X_data[shuffle[:split_1]], \n",
    "                 'targets': Y_data[shuffle[:split_1]]}\n",
    "        valid = {'inputs': X_data[shuffle[split_1:split_2]], \n",
    "                 'targets': Y_data[shuffle[split_1:split_2]]}\n",
    "        test = {'inputs': X_data[shuffle[split_2:]], \n",
    "                 'targets': Y_data[shuffle[split_2:]]}\n",
    "\n",
    "        print ('Data extraction and dict construction completed in: ' + mf.sectotime(time.time() - starttime))\n",
    "\n",
    "        simalign_file = datafiles[t][1]\n",
    "        #Get the full secondary structure and sequence consensus from the emission\n",
    "        SS = mf.getSSconsensus(simalign_file)\n",
    "        SQ = mf.getSQconsensus(simalign_file)\n",
    "\n",
    "        #Get the ungapped sequence and the indices of ungapped nucleotides\n",
    "        _, ugSS, ugidx = mf.rm_consensus_gaps(X_data, SS)\n",
    "        _, ugSQ, _ = mf.rm_consensus_gaps(X_data, SQ)\n",
    "\n",
    "\n",
    "        #Get the sequence and indices of the conserved base pairs\n",
    "        bpchars = ['(',')','<','>','{','}']\n",
    "        sig_bpchars = ['<','>']\n",
    "        bpidx, bpSS, nonbpidx = mf.sigbasepair(SS, bpchars)\n",
    "        numbp = len(bpidx)\n",
    "        numug = len(ugidx)\n",
    "\n",
    "        #Get the bpug information\n",
    "        bpugSQ, bpugidx = mf.bpug(ugidx, bpidx, SQ)\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        '''SAVE PATHS AND PARAMETERS'''\n",
    "        params_results = '../../results'\n",
    "\n",
    "        modelarch = 'resbind'\n",
    "        trial = t + '_tp%.0f'%(trainportion*100)\n",
    "        modelsavename = '%s_%s'%(modelarch, trial)\n",
    "        \n",
    "        \n",
    "        '''BUILD NEURAL NETWORK'''\n",
    "\n",
    "        def cnn_model(input_shape, output_shape):\n",
    "\n",
    "            # create model\n",
    "            layer1 = {'layer': 'input', #41\n",
    "                  'input_shape': input_shape\n",
    "                  }\n",
    "            layer2 = {'layer': 'conv1d',\n",
    "                  'num_filters': 96,\n",
    "                  'filter_size': input_shape[1]-29,\n",
    "                  'norm': 'batch',\n",
    "                  'activation': 'relu',\n",
    "                  'dropout': 0.3,\n",
    "                  'padding': 'VALID',\n",
    "                  }\n",
    "            layer3 = {'layer': 'conv1d_residual',\n",
    "                  'filter_size': 5,\n",
    "                  'function': 'relu',\n",
    "                  'dropout_block': 0.1,\n",
    "                  'dropout': 0.3,\n",
    "                  'mean_pool': 10,\n",
    "                  }\n",
    "\n",
    "            layer4 = {'layer': 'dense',        # input, conv1d, dense, conv1d_residual, dense_residual, conv1d_transpose,\n",
    "                                          # concat, embedding, variational_normal, variational_softmax, + more\n",
    "                'num_units': 196,\n",
    "                'norm': 'batch',          # if removed, automatically adds bias instead\n",
    "                'activation': 'relu',     # or leaky_relu, prelu, sigmoid, tanh, etc\n",
    "                'dropout': 0.5,           # if removed, default is no dropout\n",
    "                   }\n",
    "\n",
    "\n",
    "            layer5 = {'layer': 'dense',\n",
    "                  'num_units': output_shape[1],\n",
    "                  'activation': 'sigmoid'\n",
    "                  }\n",
    "\n",
    "            model_layers = [layer1, layer2, layer3, layer4, layer5]\n",
    "\n",
    "            # optimization parameters\n",
    "            optimization = {\"objective\": \"binary\",\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"learning_rate\": 0.0003,\n",
    "                        \"l2\": 1e-5,\n",
    "                        #\"label_smoothing\": 0.05,\n",
    "                        #\"l1\": 1e-6,\n",
    "                        }\n",
    "            return model_layers, optimization\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # get shapes of inputs and targets\n",
    "        input_shape = list(train['inputs'].shape)\n",
    "        input_shape[0] = None\n",
    "        output_shape = train['targets'].shape\n",
    "\n",
    "        # load model parameters\n",
    "        model_layers, optimization = cnn_model(input_shape, output_shape)\n",
    "\n",
    "        # build neural network class\n",
    "        nnmodel = nn.NeuralNet(seed=247)\n",
    "        nnmodel.build_layers(model_layers, optimization)\n",
    "\n",
    "        # compile neural trainer\n",
    "        save_path = os.path.join(params_results, exp)\n",
    "        param_path = os.path.join(save_path, modelsavename)\n",
    "        nntrainer = nn.NeuralTrainer(nnmodel, save='best', file_path=param_path)\n",
    "\n",
    "        '''TEST'''\n",
    "        sess = utils.initialize_session()\n",
    "\n",
    "        # set best parameters\n",
    "        nntrainer.set_best_parameters(sess)\n",
    "                \n",
    "        # test model\n",
    "        loss, mean_vals, std_vals = nntrainer.test_model(sess, test, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183.74885156967613"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100000*(1-mean_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['inputs'].shape[0] - test['inputs'].shape[0]*mean_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
